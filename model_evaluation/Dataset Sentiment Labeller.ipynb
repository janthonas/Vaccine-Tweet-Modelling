{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564932a6-8c29-41fd-9bc1-06ccf967da7e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd4f59d9-06d2-4775-94af-74e259e63192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import contractions\n",
    "\n",
    "# Machine Learning\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1efa4-9341-4531-be19-fddc477d674d",
   "metadata": {},
   "source": [
    "## Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5589dda2-6046-4030-b0b6-4c0219fc9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Model\n",
    "sentiment_model_dir = '../models/sentiment_emotion_models/sentiment_pn_model'\n",
    "\n",
    "sentiment_model_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_dir, num_labels=2)\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_dir, num_labels=2)\n",
    "\n",
    "# Official Reporting Model\n",
    "reporting_model_dir = '../models/sentiment_emotion_models/official_report_emotion_model'\n",
    "\n",
    "reporting_model_tokenizer = AutoTokenizer.from_pretrained(reporting_model_dir, num_labels=2)\n",
    "reporting_model = AutoModelForSequenceClassification.from_pretrained(reporting_model_dir, num_labels=2)\n",
    "\n",
    "# Joyful Emotion Model\n",
    "joyful_model_dir = '../models/sentiment_emotion_models/joyful_emotion_model'\n",
    "\n",
    "joyful_model_tokenizer = AutoTokenizer.from_pretrained(joyful_model_dir, num_labels=2)\n",
    "joyful_model = AutoModelForSequenceClassification.from_pretrained(joyful_model_dir, num_labels=2)\n",
    "\n",
    "# Love Emotion Model\n",
    "love_model_dir = '../models/sentiment_emotion_models/love_emotion_model'\n",
    "\n",
    "love_model_tokenizer = AutoTokenizer.from_pretrained(love_model_dir, num_labels=2)\n",
    "love_model = AutoModelForSequenceClassification.from_pretrained(love_model_dir, num_labels=2)\n",
    "\n",
    "# Anger Emotion Model\n",
    "anger_model_dir = '../models/sentiment_emotion_models/anger_emotion_model'\n",
    "\n",
    "anger_model_tokenizer = AutoTokenizer.from_pretrained(anger_model_dir, num_labels=2)\n",
    "anger_model = AutoModelForSequenceClassification.from_pretrained(anger_model_dir, num_labels=2)\n",
    "\n",
    "# Sadness Emotion Model\n",
    "sadness_model_dir = '../models/sentiment_emotion_models/sadness_emotion_model'\n",
    "\n",
    "sadness_model_tokenizer = AutoTokenizer.from_pretrained(sadness_model_dir, num_labels=2)\n",
    "sadness_model = AutoModelForSequenceClassification.from_pretrained(sadness_model_dir, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4340a-59e3-4122-a9c2-4632f789709e",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "415a01e7-5a6d-4fe6-9e5f-e2ecdafab35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Dataset\n",
    "pruned_network_df = pd.read_csv('../twitter_data/network_data/pruned_network_data.csv')\n",
    "\n",
    "# Media\n",
    "pruned_media_users_df = pd.read_csv('../twitter_data/network_data/pruned_media_users.csv')\n",
    "\n",
    "# Medicine and Researchers\n",
    "pruned_medicine_and_research_users_df = pd.read_csv('../twitter_data/network_data/pruned_medicine_and_research_users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c938772-1ec9-49bf-aeef-f6a28612eb30",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c396d-6874-4e77-b86f-191faff5eef8",
   "metadata": {},
   "source": [
    "### Pre-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1cb5b3b0-9fd9-4471-96ce-8a28b249aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(doc):\n",
    "    return re.sub(r'http\\S+', '', doc)\n",
    "\n",
    "def convert_emojis(doc):\n",
    "    # delimiters are what is used around the emoji description, in this case spaces are used\n",
    "    return emoji.replace_emoji(doc, replace='')\n",
    "\n",
    "def remove_hashtags(doc):\n",
    "    return doc.replace('#', '')\n",
    "    #return re.sub(r'#\\w+', '', doc)\n",
    "\n",
    "def remove_numbers(doc):\n",
    "    return re.sub(r'\\d+', '', doc)\n",
    "\n",
    "def remove_user_mentions(doc):\n",
    "    return re.sub(r'@\\w+', '', doc)\n",
    "\n",
    "def fix_contractions(doc):\n",
    "    return contractions.fix(doc)\n",
    "\n",
    "def remove_punctuation(doc):\n",
    "    return re.sub(r'[^\\w\\s]', '', doc)\n",
    "\n",
    "def remove_amp(doc):\n",
    "    return re.sub(r'\\bamp\\b', ' and ', doc).strip() # strip removes the surrounding white space\n",
    "\n",
    "def remove_special_character_combinations(doc):\n",
    "    # Remove all combinations of \\r and \\n in any order\n",
    "    cleaned_text = re.sub(r'[\\r\\n\\xa0]+', '', doc)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_non_english_characters(doc):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', doc)\n",
    "\n",
    "def lowercase_doc(doc):\n",
    "    return doc.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a8207-8c30-4ed4-8ad6-65feef878023",
   "metadata": {},
   "source": [
    "### Pre-Processing Master Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f5daa54-7e98-4e17-b055-98628792f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(doc):\n",
    "    doc = remove_urls(doc)\n",
    "    doc = convert_emojis(doc)\n",
    "    doc = remove_hashtags(doc)\n",
    "    #doc = remove_numbers(doc)\n",
    "    doc = remove_user_mentions(doc)\n",
    "    doc = fix_contractions(doc)\n",
    "    #doc = remove_punctuation(doc)\n",
    "    doc = remove_amp(doc)\n",
    "    doc = remove_special_character_combinations(doc)\n",
    "    doc = remove_non_english_characters(doc)\n",
    "    #doc = lowercase_doc(doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09ca1d-3496-4d1e-b710-1fc139f05fae",
   "metadata": {},
   "source": [
    "### Applying the Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbab6403-303d-4f47-ba9d-9e781c34bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_network_df['Tweet'] = pruned_network_df['Tweet'].apply(preprocess_tweet)\n",
    "pruned_media_users_df['Tweet'] = pruned_media_users_df['Tweet'].apply(preprocess_tweet)\n",
    "pruned_medicine_and_research_users_df['Tweet'] = pruned_medicine_and_research_users_df['Tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211418a-ceb2-4ab3-846d-4cd16fc4dae7",
   "metadata": {},
   "source": [
    "## Dataset Labeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c1ca79e-3be5-4653-8f34-75f1894284b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=280)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb3a5a86-6f19-4679-8bc1-8073ef5482ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "1.7887807670291929%\n",
      "3.5775615340583857%\n",
      "5.366342301087579%\n",
      "7.1551230681167715%\n",
      "8.943903835145965%\n",
      "10.732684602175159%\n",
      "12.521465369204352%\n",
      "14.310246136233543%\n",
      "16.099026903262736%\n",
      "17.88780767029193%\n",
      "19.676588437321122%\n",
      "21.465369204350317%\n",
      "23.254149971379505%\n",
      "25.042930738408703%\n",
      "26.831711505437895%\n",
      "28.620492272467086%\n",
      "30.40927303949628%\n",
      "32.19805380652547%\n",
      "33.98683457355467%\n",
      "35.77561534058386%\n",
      "37.56439610761305%\n",
      "39.353176874642244%\n",
      "41.14195764167144%\n",
      "42.930738408700634%\n",
      "44.71951917572982%\n",
      "46.50829994275901%\n",
      "48.29708070978821%\n",
      "50.085861476817406%\n",
      "51.874642243846594%\n",
      "53.66342301087579%\n",
      "55.452203777904984%\n",
      "57.24098454493417%\n",
      "59.02976531196337%\n",
      "60.81854607899256%\n",
      "62.60732684602175%\n",
      "64.39610761305094%\n",
      "66.18488838008014%\n",
      "67.97366914710933%\n",
      "69.76244991413853%\n",
      "71.55123068116772%\n",
      "73.3400114481969%\n",
      "75.1287922152261%\n",
      "76.9175729822553%\n",
      "78.70635374928449%\n",
      "80.49513451631368%\n",
      "82.28391528334288%\n",
      "84.07269605037206%\n",
      "85.86147681740127%\n",
      "87.65025758443046%\n",
      "89.43903835145964%\n",
      "91.22781911848884%\n",
      "93.01659988551802%\n",
      "94.80538065254723%\n",
      "96.59416141957642%\n",
      "98.3829421866056%\n"
     ]
    }
   ],
   "source": [
    "# Predicting sentiment for the individual tweets\n",
    "sentiments = [0, 1]\n",
    "predicted_sentiment_list = []\n",
    "predicted_official_report_list = []\n",
    "predicted_joyful_list = []\n",
    "predicted_love_list = []\n",
    "predicted_anger_list = []\n",
    "predicted_sadness_list = []\n",
    "\n",
    "for index, row in pruned_medicine_and_research_users_df.iterrows():\n",
    "\n",
    "    text = row['Tweet']\n",
    "\n",
    "    # Calculate probabilities for sentiment\n",
    "    predicted_sentiment = analyze_sentiment(text, sentiment_model, sentiment_model_tokenizer).tolist()\n",
    "    sentiment_max_index = predicted_sentiment[0].index(max(predicted_sentiment[0]))\n",
    "\n",
    "    # Calculate probabilities for official report\n",
    "    predicted_official_report = analyze_sentiment(text, reporting_model, reporting_model_tokenizer).tolist()\n",
    "    official_report_max_index = predicted_official_report[0].index(max(predicted_official_report[0]))\n",
    "\n",
    "    # Calculate probabilities for joyful\n",
    "    predicted_joyful = analyze_sentiment(text, joyful_model, joyful_model_tokenizer).tolist()\n",
    "    joyful_max_index = predicted_joyful[0].index(max(predicted_joyful[0]))\n",
    "\n",
    "    # Calculate probabilities for love\n",
    "    predicted_love = analyze_sentiment(text, love_model, love_model_tokenizer).tolist()\n",
    "    love_max_index = predicted_love[0].index(max(predicted_love[0]))\n",
    "\n",
    "    # Calculate probabilities for anger\n",
    "    predicted_anger = analyze_sentiment(text, anger_model, anger_model_tokenizer).tolist()\n",
    "    anger_max_index = predicted_anger[0].index(max(predicted_anger[0]))\n",
    "\n",
    "    # Calculate probabilities for anger\n",
    "    predicted_sadness = analyze_sentiment(text, sadness_model, sadness_model_tokenizer).tolist()\n",
    "    sadness_max_index = predicted_sadness[0].index(max(predicted_sadness[0]))\n",
    "\n",
    "    # Saving sentiments in a list\n",
    "    predicted_sentiment_list.append(sentiment_max_index)\n",
    "    predicted_official_report_list.append(official_report_max_index)\n",
    "    predicted_joyful_list.append(joyful_max_index)\n",
    "    predicted_love_list.append(love_max_index)\n",
    "    predicted_anger_list.append(anger_max_index)\n",
    "    predicted_sadness_list.append(sadness_max_index)\n",
    "\n",
    "    if(index % 500 == 0):\n",
    "        perc_current = (index / len(pruned_medicine_and_research_users_df)) * 100\n",
    "        print(str(perc_current) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98397085-e5d7-4e42-8a50-a344b2865277",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_network_df = pruned_medicine_and_research_users_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8608f8de-0b6f-424a-bdf5-d3f83231183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_network_df['sentiment_results'] = predicted_sentiment_list\n",
    "test_network_df['official_report_results'] = predicted_official_report_list\n",
    "test_network_df['joyful_results'] = predicted_joyful_list\n",
    "test_network_df['love_results'] = predicted_love_list\n",
    "test_network_df['anger_results'] = predicted_anger_list\n",
    "test_network_df['sadness_results'] = predicted_sadness_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1802cf5-fcc9-465a-9d05-8d6c577d5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_network_df.to_csv('pruned_labelled_medicine_and_research_users.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "438e0a99-a188-45b8-ac30-24f511034a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vertex1</th>\n",
       "      <th>Vertex2</th>\n",
       "      <th>Relationship_type</th>\n",
       "      <th>Relationship Date (UTC)</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Lang_code</th>\n",
       "      <th>Tweet Date (UTC)</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Conversation_ID</th>\n",
       "      <th>Author_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Sourcetweet_id</th>\n",
       "      <th>Sourcetweet_text</th>\n",
       "      <th>Sourcetweet_author_id</th>\n",
       "      <th>Sourcetweet_lang</th>\n",
       "      <th>sentiment_results</th>\n",
       "      <th>official_report_results</th>\n",
       "      <th>joyful_results</th>\n",
       "      <th>love_results</th>\n",
       "      <th>anger_results</th>\n",
       "      <th>sadness_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>michaelmina_lab</td>\n",
       "      <td>diseaseecology</td>\n",
       "      <td>Quote</td>\n",
       "      <td>2020-12-01T00:02:24.000Z</td>\n",
       "      <td>Speaking of Kids and infections.</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-12-01T00:02:24.000Z</td>\n",
       "      <td>1333562054498783233</td>\n",
       "      <td>1.333350e+18</td>\n",
       "      <td>1094762324097822720</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333532e+18</td>\n",
       "      <td>Age-patterns of infection from random sampling...</td>\n",
       "      <td>1.647830e+09</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angie_rasmussen</td>\n",
       "      <td>paimadhu</td>\n",
       "      <td>Quote</td>\n",
       "      <td>2020-12-01T00:04:28.000Z</td>\n",
       "      <td>\"In practice, by announcing a 9,500 price tag ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-12-01T00:04:28.000Z</td>\n",
       "      <td>1333562574877573120</td>\n",
       "      <td>1.333563e+18</td>\n",
       "      <td>394087611</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333551e+18</td>\n",
       "      <td>My new @forbes piece is about \"prestige journa...</td>\n",
       "      <td>3.419251e+09</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>florian_krammer</td>\n",
       "      <td>kindrachukjason</td>\n",
       "      <td>Quote</td>\n",
       "      <td>2020-12-01T00:08:17.000Z</td>\n",
       "      <td>Awesome!</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-12-01T00:08:17.000Z</td>\n",
       "      <td>1333563532475031553</td>\n",
       "      <td>1.333564e+18</td>\n",
       "      <td>704282873231237121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333563e+18</td>\n",
       "      <td>💥 https://t.co/iZldo8Cruo</td>\n",
       "      <td>1.071979e+18</td>\n",
       "      <td>und</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>florian_krammer</td>\n",
       "      <td>rover829</td>\n",
       "      <td>Quote</td>\n",
       "      <td>2020-12-01T00:08:51.000Z</td>\n",
       "      <td>Good!!!</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-12-01T00:08:51.000Z</td>\n",
       "      <td>1333563678034190337</td>\n",
       "      <td>1.333564e+18</td>\n",
       "      <td>704282873231237121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333561e+18</td>\n",
       "      <td>Reuters:  DR. SCOTT ATLAS HAS RESIGNED AS SPEC...</td>\n",
       "      <td>1.268167e+08</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angie_rasmussen</td>\n",
       "      <td>angie_rasmussen</td>\n",
       "      <td>Tweet</td>\n",
       "      <td>2020-12-01T00:08:53.000Z</td>\n",
       "      <td>Out with a whimper</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-12-01T00:08:53.000Z</td>\n",
       "      <td>1333563683952156672</td>\n",
       "      <td>1.333564e+18</td>\n",
       "      <td>394087611</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27947</th>\n",
       "      <td>michaelmina_lab</td>\n",
       "      <td>michaelmina_lab</td>\n",
       "      <td>Tweet</td>\n",
       "      <td>2022-02-23T22:40:42.000Z</td>\n",
       "      <td>I just received this question:[Michael,] Any t...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-02-23T22:40:42.000Z</td>\n",
       "      <td>1496616031753670656</td>\n",
       "      <td>1.496616e+18</td>\n",
       "      <td>1094762324097822720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27948</th>\n",
       "      <td>doctorsoumya</td>\n",
       "      <td>doctorsoumya</td>\n",
       "      <td>Tweet</td>\n",
       "      <td>2022-02-23T22:44:17.000Z</td>\n",
       "      <td>WHO creates training hub to boost pharmaceutic...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-02-23T22:44:17.000Z</td>\n",
       "      <td>1496616936008003586</td>\n",
       "      <td>1.496617e+18</td>\n",
       "      <td>2855536962</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27949</th>\n",
       "      <td>michaelmina_lab</td>\n",
       "      <td>michaelmina_lab</td>\n",
       "      <td>Quote</td>\n",
       "      <td>2022-02-23T22:50:37.000Z</td>\n",
       "      <td>2 years ago today!Testing in US was already fa...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-02-23T22:50:37.000Z</td>\n",
       "      <td>1496618526261399554</td>\n",
       "      <td>1.496619e+18</td>\n",
       "      <td>1094762324097822720</td>\n",
       "      <td>...</td>\n",
       "      <td>1.231504e+18</td>\n",
       "      <td>Reminder: As of today (Feb 23), the US remains...</td>\n",
       "      <td>1.094762e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27950</th>\n",
       "      <td>gregggonsalves</td>\n",
       "      <td>gregggonsalves</td>\n",
       "      <td>Tweet</td>\n",
       "      <td>2022-02-23T23:36:08.000Z</td>\n",
       "      <td>OMG. I laughed so hard. Elmo replaces Timothee...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-02-23T23:36:08.000Z</td>\n",
       "      <td>1496629982013050882</td>\n",
       "      <td>1.496630e+18</td>\n",
       "      <td>30844417</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27951</th>\n",
       "      <td>phylogenomics</td>\n",
       "      <td>phylogenomics</td>\n",
       "      <td>Tweet</td>\n",
       "      <td>2022-02-23T23:51:29.000Z</td>\n",
       "      <td>Sorry BGI - am unimpressed - tell me about you...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-02-23T23:51:29.000Z</td>\n",
       "      <td>1496633846246227972</td>\n",
       "      <td>1.496634e+18</td>\n",
       "      <td>15154811</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27952 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Vertex1          Vertex2 Relationship_type  \\\n",
       "0      michaelmina_lab   diseaseecology             Quote   \n",
       "1      angie_rasmussen         paimadhu             Quote   \n",
       "2      florian_krammer  kindrachukjason             Quote   \n",
       "3      florian_krammer         rover829             Quote   \n",
       "4      angie_rasmussen  angie_rasmussen             Tweet   \n",
       "...                ...              ...               ...   \n",
       "27947  michaelmina_lab  michaelmina_lab             Tweet   \n",
       "27948     doctorsoumya     doctorsoumya             Tweet   \n",
       "27949  michaelmina_lab  michaelmina_lab             Quote   \n",
       "27950   gregggonsalves   gregggonsalves             Tweet   \n",
       "27951    phylogenomics    phylogenomics             Tweet   \n",
       "\n",
       "        Relationship Date (UTC)  \\\n",
       "0      2020-12-01T00:02:24.000Z   \n",
       "1      2020-12-01T00:04:28.000Z   \n",
       "2      2020-12-01T00:08:17.000Z   \n",
       "3      2020-12-01T00:08:51.000Z   \n",
       "4      2020-12-01T00:08:53.000Z   \n",
       "...                         ...   \n",
       "27947  2022-02-23T22:40:42.000Z   \n",
       "27948  2022-02-23T22:44:17.000Z   \n",
       "27949  2022-02-23T22:50:37.000Z   \n",
       "27950  2022-02-23T23:36:08.000Z   \n",
       "27951  2022-02-23T23:51:29.000Z   \n",
       "\n",
       "                                                   Tweet Lang_code  \\\n",
       "0                       Speaking of Kids and infections.        en   \n",
       "1      \"In practice, by announcing a 9,500 price tag ...        en   \n",
       "2                                               Awesome!        en   \n",
       "3                                                Good!!!        en   \n",
       "4                                     Out with a whimper        en   \n",
       "...                                                  ...       ...   \n",
       "27947  I just received this question:[Michael,] Any t...        en   \n",
       "27948  WHO creates training hub to boost pharmaceutic...        en   \n",
       "27949  2 years ago today!Testing in US was already fa...        en   \n",
       "27950  OMG. I laughed so hard. Elmo replaces Timothee...        en   \n",
       "27951  Sorry BGI - am unimpressed - tell me about you...        en   \n",
       "\n",
       "               Tweet Date (UTC)             Tweet_ID  Conversation_ID  \\\n",
       "0      2020-12-01T00:02:24.000Z  1333562054498783233     1.333350e+18   \n",
       "1      2020-12-01T00:04:28.000Z  1333562574877573120     1.333563e+18   \n",
       "2      2020-12-01T00:08:17.000Z  1333563532475031553     1.333564e+18   \n",
       "3      2020-12-01T00:08:51.000Z  1333563678034190337     1.333564e+18   \n",
       "4      2020-12-01T00:08:53.000Z  1333563683952156672     1.333564e+18   \n",
       "...                         ...                  ...              ...   \n",
       "27947  2022-02-23T22:40:42.000Z  1496616031753670656     1.496616e+18   \n",
       "27948  2022-02-23T22:44:17.000Z  1496616936008003586     1.496617e+18   \n",
       "27949  2022-02-23T22:50:37.000Z  1496618526261399554     1.496619e+18   \n",
       "27950  2022-02-23T23:36:08.000Z  1496629982013050882     1.496630e+18   \n",
       "27951  2022-02-23T23:51:29.000Z  1496633846246227972     1.496634e+18   \n",
       "\n",
       "                 Author_ID  ... Sourcetweet_id  \\\n",
       "0      1094762324097822720  ...   1.333532e+18   \n",
       "1                394087611  ...   1.333551e+18   \n",
       "2       704282873231237121  ...   1.333563e+18   \n",
       "3       704282873231237121  ...   1.333561e+18   \n",
       "4                394087611  ...            NaN   \n",
       "...                    ...  ...            ...   \n",
       "27947  1094762324097822720  ...            NaN   \n",
       "27948           2855536962  ...            NaN   \n",
       "27949  1094762324097822720  ...   1.231504e+18   \n",
       "27950             30844417  ...            NaN   \n",
       "27951             15154811  ...            NaN   \n",
       "\n",
       "                                        Sourcetweet_text  \\\n",
       "0      Age-patterns of infection from random sampling...   \n",
       "1      My new @forbes piece is about \"prestige journa...   \n",
       "2                              💥 https://t.co/iZldo8Cruo   \n",
       "3      Reuters:  DR. SCOTT ATLAS HAS RESIGNED AS SPEC...   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "27947                                                NaN   \n",
       "27948                                                NaN   \n",
       "27949  Reminder: As of today (Feb 23), the US remains...   \n",
       "27950                                                NaN   \n",
       "27951                                                NaN   \n",
       "\n",
       "      Sourcetweet_author_id  Sourcetweet_lang sentiment_results  \\\n",
       "0              1.647830e+09                en                 0   \n",
       "1              3.419251e+09                en                 1   \n",
       "2              1.071979e+18               und                 1   \n",
       "3              1.268167e+08                en                 1   \n",
       "4                       NaN               NaN                 0   \n",
       "...                     ...               ...               ...   \n",
       "27947                   NaN               NaN                 0   \n",
       "27948                   NaN               NaN                 1   \n",
       "27949          1.094762e+18                en                 0   \n",
       "27950                   NaN               NaN                 1   \n",
       "27951                   NaN               NaN                 0   \n",
       "\n",
       "       official_report_results joyful_results  love_results  anger_results  \\\n",
       "0                            0              0             0              0   \n",
       "1                            0              0             0              1   \n",
       "2                            0              0             1              0   \n",
       "3                            0              0             1              0   \n",
       "4                            0              0             0              0   \n",
       "...                        ...            ...           ...            ...   \n",
       "27947                        0              0             0              0   \n",
       "27948                        0              0             0              0   \n",
       "27949                        0              0             0              0   \n",
       "27950                        0              1             0              0   \n",
       "27951                        0              0             0              0   \n",
       "\n",
       "       sadness_results  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "27947                0  \n",
       "27948                1  \n",
       "27949                0  \n",
       "27950                0  \n",
       "27951                0  \n",
       "\n",
       "[27952 rows x 23 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_network_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e93d2-a338-432d-b3a9-97f10cc597f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ta)",
   "language": "python",
   "name": "ta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
