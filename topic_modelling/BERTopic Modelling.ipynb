{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eea8c2e-b329-48e7-9a2a-237c8f32aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import spacy\n",
    "# Spacy's english model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# used to fix contractions such as I'll to I will\n",
    "import contractions\n",
    "\n",
    "from bertopic.representation import KeyBERTInspired, PartOfSpeech, MaximalMarginalRelevance\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137eba8a-6eb0-4117-8f4b-54907928b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "tweet_data_fp = '../twitter_data/custom_data/pruned_media_users.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390d7629-e6dc-4e54-9496-db8b8a4794c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_df = pd.read_csv(tweet_data_fp)\n",
    "tweet_data_df = tweet_data_df[tweet_data_df['Lang_code'] == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f99876-7723-48d4-8123-c45c346bac07",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c189bca0-0e98-43af-9058-05ce7dc97977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering documents\n",
    "docs = tweet_data_df['Tweet'].tolist()\n",
    "pruned_docs = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed677dc-d95a-4425-abc3-0d4dff656277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruned_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64681897-7848-4981-b741-793375070aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best to err on the side of caution when pre-processing:\n",
    "# https://maartengr.github.io/BERTopic/faq.html#should-i-preprocess-the-data\n",
    "\n",
    "# Removal of links\n",
    "def remove_urls(doc):\n",
    "    return re.sub(r'http\\S+', '', doc)\n",
    "\n",
    "pruned_docs = [remove_urls(doc) for doc in pruned_docs]\n",
    "\n",
    "# Converting hashtags into words\n",
    "# Or removing the hashtag and word entirely\n",
    "# Hashtags are converted to standard words as part of the tokenizer\n",
    "def remove_hashtags(doc):\n",
    "    return doc.replace('#', '')\n",
    "    #return re.sub(r'#\\w+', '', doc)\n",
    "\n",
    "pruned_docs = [remove_hashtags(doc) for doc in pruned_docs]\n",
    "\n",
    "# Converting mentions into words\n",
    "def remove_numbers(doc):\n",
    "    return re.sub(r'\\d+', '', doc)\n",
    "\n",
    "pruned_docs = [remove_numbers(doc) for doc in pruned_docs]\n",
    "\n",
    "# Function to remove user mentions\n",
    "def remove_user_mentions(doc):\n",
    "    return re.sub(r'@\\w+', '', doc)\n",
    "\n",
    "pruned_docs = [remove_user_mentions(doc) for doc in pruned_docs]\n",
    "\n",
    "def fix_contractions(doc):\n",
    "    return contractions.fix(doc)\n",
    "\n",
    "pruned_docs = [fix_contractions(doc) for doc in pruned_docs]\n",
    "\n",
    "# Remove punctuation \n",
    "# Punctuation is removed as part of the tokenizer\n",
    "def remove_punctuation(doc):\n",
    "    return re.sub(r'[^\\w\\s]', '', doc)\n",
    "\n",
    "pruned_docs = [remove_punctuation(doc) for doc in pruned_docs]\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(doc):\n",
    "    return ' '.join([word for word in doc.split() if word.lower() not in stop_words])\n",
    "\n",
    "pruned_docs = [remove_stopwords(doc) for doc in pruned_docs]\n",
    "\n",
    "# Lemmatize the text\n",
    "def lemmatize_text(doc):\n",
    "    doc = nlp(doc)\n",
    "    return ' '.join([token.lemma_ for token in doc if token.lemma_ not in stop_words and not token.is_punct and not token.is_space])\n",
    "\n",
    "pruned_docs = [lemmatize_text(doc) for doc in pruned_docs]\n",
    "\n",
    "# Remove the 'amp' word\n",
    "def remove_amp(doc):\n",
    "    return re.sub(r'\\bamp\\b', '', doc).strip() # strip removes the surrounding white space\n",
    "\n",
    "pruned_docs = [remove_amp(doc) for doc in pruned_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf9efa6-0c1e-4d26-9947-f528158dd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = lambda s: re.findall( '\\w+', s.lower() )\n",
    "\n",
    "pruned_docs_split = [ tokenizer(doc) for doc in  pruned_docs ]\n",
    "\n",
    "# Combine the inner lists into sentences\n",
    "pruned_docs_tokenized = [' '.join(words) for words in pruned_docs_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a47e15-2619-4960-be6c-7590dc179f2f",
   "metadata": {},
   "source": [
    "## Performing BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa536cb-22b8-4134-8c99-7231e1eca3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# None of these give strong results\n",
    "#representation_model = KeyBERTInspired() \n",
    "#representation_model = PartOfSpeech(\"en_core_web_sm\") \n",
    "#representation_model = MaximalMarginalRelevance(diversity=0.8) \n",
    "\n",
    "# Topic modelling\n",
    "bertopic_model = BERTopic()\n",
    "topics, probs = bertopic_model.fit_transform(pruned_docs_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5adaba55-e623-4933-b254-37e54e88bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_topic_df = bertopic_model.get_document_info(pruned_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31d940-4a06-4c60-b855-6bc61095dcab",
   "metadata": {},
   "source": [
    "## Calculating Topic Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c0338e-7c65-4124-b85e-80666feea655",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = bertopic_model.get_topic_info()\n",
    "topics = topic_info['Representation'].tolist()\n",
    "\n",
    "word2id = Dictionary(pruned_docs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed7b722a-330c-481e-aec5-14e26255e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CoherenceModel(topics=topics, \n",
    "                    texts=pruned_docs_split,\n",
    "                    coherence='c_npmi',  # c_npmi was used in the bertopic serbian research paper\n",
    "                    dictionary=word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8c27c0-6196-4b2e-8e6d-6a14d4728299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "coherence_per_topic = cm.get_coherence_per_topic()\n",
    "macro_topic_coherence = sum(coherence_per_topic) / len(coherence_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa2ecbd0-6b67-4ca7-b159-e8547221cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10376349222330807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This returns 0.02 when set to npmi, the serbian research return -0.042 as their best score\n",
    "# This returns 0.511 when set to c_v, this is a good coherence score\n",
    "# When removing non-english words and links this drops to 0.44\n",
    "# When adding lemmatization this goes up to 0.46\n",
    "# Removing numbers drop to 0.4567\n",
    "macro_topic_coherence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f74f6eae-11b2-4c2e-a820-d9e5b34ec451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be7ca0-ada5-47d3-b662-8e7233cdda4e",
   "metadata": {},
   "source": [
    "## Calculating Topic Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0070bd1f-1b05-4f7a-8d3c-c62980f37da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found here: https://github.com/silviatti/topic-model-diversity/blob/master/diversity_metrics.py\n",
    "def proportion_unique_words(topics, topk=10):\n",
    "    \"\"\"\n",
    "    compute the proportion of unique words\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    topics: a list of lists of words\n",
    "    topk: top k words on which the topic diversity will be computed (There are 10 words in each topic)\n",
    "    \"\"\"\n",
    "    if topk > len(topics[0]):\n",
    "        raise Exception('Words in topics are less than '+str(topk))\n",
    "    else:\n",
    "        unique_words = set()\n",
    "        for topic in topics:\n",
    "            unique_words = unique_words.union(set(topic[:topk]))\n",
    "        puw = len(unique_words) / (topk * len(topics))\n",
    "        return puw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de26953-bf2b-4641-b5bb-4d74cd4a8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def pairwise_jaccard_diversity(topics, topk=10):\n",
    "    '''\n",
    "    compute the average pairwise jaccard distance between the topics \n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    topics: a list of lists of words\n",
    "    topk: top k words on which the topic diversity\n",
    "          will be computed (There are 10 words in each topic)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pjd: average pairwise jaccard distance\n",
    "    '''\n",
    "    dist = 0\n",
    "    count = 0\n",
    "    for list1, list2 in combinations(topics, 2):\n",
    "        js = 1 - len(set(list1).intersection(set(list2)))/len(set(list1).union(set(list2)))\n",
    "        dist = dist + js\n",
    "        count = count + 1\n",
    "    return dist/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d3af1b0-d686-4e50-9b60-64e7e75d460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066666666666666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first inputs the topics, the second inputs the number of words in each topic\n",
    "proportion_unique_words(topics, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb47e8c9-121b-4ab1-9cc7-e1a580fa97d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842445998363061"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_jaccard_diversity(topics, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b9071-66d7-47d0-87d3-368858e9ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_info['Representation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8665a506-14cc-464e-a31b-b2eb4c33022b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ta)",
   "language": "python",
   "name": "ta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
