{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9eea8c2e-b329-48e7-9a2a-237c8f32aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "137eba8a-6eb0-4117-8f4b-54907928b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "tweet_data_fp = 'twitter_data/Tweets_data_original_copy.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "390d7629-e6dc-4e54-9496-db8b8a4794c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_df = pd.read_excel(tweet_data_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f99876-7723-48d4-8123-c45c346bac07",
   "metadata": {},
   "source": [
    "## Performing BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c189bca0-0e98-43af-9058-05ce7dc97977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering documents\n",
    "docs = tweet_data_df['text'].tolist()\n",
    "\n",
    "pruned_docs = docs[::10]\n",
    "\n",
    "tokenizer = lambda s: re.findall( '\\w+', s.lower() )\n",
    "\n",
    "pruned_docs_split = [ tokenizer(doc) for doc in  pruned_docs ]\n",
    "\n",
    "# Combine the inner lists into sentences\n",
    "pruned_docs_tokenized = [' '.join(words) for words in pruned_docs_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9fa536cb-22b8-4134-8c99-7231e1eca3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Topic modelling\n",
    "bertopic_model = BERTopic()\n",
    "topics, probs = bertopic_model.fit_transform(pruned_docs_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5adaba55-e623-4933-b254-37e54e88bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_topic_df = bertopic_model.get_document_info(pruned_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3e3d833f-3619-4a58-a857-e424397c387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_topic_df['Topic'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31d940-4a06-4c60-b855-6bc61095dcab",
   "metadata": {},
   "source": [
    "## Calculating Topic Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "32c0338e-7c65-4124-b85e-80666feea655",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = bertopic_model.get_topic_info()\n",
    "topics = topic_info['Representation'].tolist()\n",
    "\n",
    "word2id = Dictionary(pruned_docs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ed7b722a-330c-481e-aec5-14e26255e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CoherenceModel(topics=topics, \n",
    "                    texts=pruned_docs_split,\n",
    "                    coherence='c_v',  # c_npmi was used in the bertopic serbian research paper\n",
    "                    dictionary=word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4c8c27c0-6196-4b2e-8e6d-6a14d4728299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "coherence_per_topic = cm.get_coherence_per_topic()\n",
    "macro_topic_coherence = sum(coherence_per_topic) / len(coherence_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fa2ecbd0-6b67-4ca7-b159-e8547221cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5113417305325562"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This returns 0.02 when set to npmi, the serbian research return -0.042 as their best score\n",
    "# This returns 0.511 when set to c_v, this is a good coherence score\n",
    "macro_topic_coherence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be7ca0-ada5-47d3-b662-8e7233cdda4e",
   "metadata": {},
   "source": [
    "## Calculating Topic Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0070bd1f-1b05-4f7a-8d3c-c62980f37da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found here: https://github.com/silviatti/topic-model-diversity/blob/master/diversity_metrics.py\n",
    "def proportion_unique_words(topics, topk=10):\n",
    "    \"\"\"\n",
    "    compute the proportion of unique words\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    topics: a list of lists of words\n",
    "    topk: top k words on which the topic diversity will be computed (There are 10 words in each topic)\n",
    "    \"\"\"\n",
    "    if topk > len(topics[0]):\n",
    "        raise Exception('Words in topics are less than '+str(topk))\n",
    "    else:\n",
    "        unique_words = set()\n",
    "        for topic in topics:\n",
    "            unique_words = unique_words.union(set(topic[:topk]))\n",
    "        puw = len(unique_words) / (topk * len(topics))\n",
    "        return puw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5de26953-bf2b-4641-b5bb-4d74cd4a8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def pairwise_jaccard_diversity(topics, topk=10):\n",
    "    '''\n",
    "    compute the average pairwise jaccard distance between the topics \n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    topics: a list of lists of words\n",
    "    topk: top k words on which the topic diversity\n",
    "          will be computed (There are 10 words in each topic)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pjd: average pairwise jaccard distance\n",
    "    '''\n",
    "    dist = 0\n",
    "    count = 0\n",
    "    for list1, list2 in combinations(topics, 2):\n",
    "        js = 1 - len(set(list1).intersection(set(list2)))/len(set(list1).union(set(list2)))\n",
    "        dist = dist + js\n",
    "        count = count + 1\n",
    "    return dist/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4d3af1b0-d686-4e50-9b60-64e7e75d460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7597435897435898"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first inputs the topics, the second inputs the number of words in each topic\n",
    "proportion_unique_words(topics, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cb47e8c9-121b-4ab1-9cc7-e1a580fa97d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984373766777069"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_jaccard_diversity(topics, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b9071-66d7-47d0-87d3-368858e9ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ta)",
   "language": "python",
   "name": "ta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
